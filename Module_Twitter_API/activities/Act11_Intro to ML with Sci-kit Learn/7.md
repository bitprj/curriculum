<!--title={Tuning our Model}-->

![Image result for grid search](https://upload.wikimedia.org/wikipedia/commons/b/b6/Hyperparameter_Optimization_using_Grid_Search.svg)

Which hyperparameters work best for our model?

We can programmatically test which combinations of hyperparameters yield the best results for us using Grid Search.

At the top, import the Grid Search class from Sklearn

```python
from sklearn.model_selection import GridSearchCV
```

Our model is SVM, which we can just create

```python
svc = svm.SVC()
```

The hyperparameters we are testing are:

* kernel &rarr; linear, rbf
* C &rarr; 1, 4, 8, 16, 32

We can store these values as a dictionary called `parameters`

```python
svc = svm.SVC()
parameters = {
    'kernel': ('linear', 'rbf')
	'C': (1,4,8,16,32)
}
```

Let's choose a cross-validation fold value of 5

```python
svc = svm.SVC()
parameters = {
    'kernel': ('linear', 'rbf')
	'C': (1,4,8,16,32)
}
cv = 5
```

Finally, we can pass all three values into `GridSearchCV`

```python
svc = svm.SVC()
parameters = {
    'kernel': ('linear', 'rbf')
	'C': (1,4,8,16,32)
}
cv = 5

clf = GridSearchCV(svc, parameters, cv)
```

We have our Grid Search class ready to go, the last thing we need to do is pass in our training data to `clf` using its `fit` method

```python
svc = svm.SVC()
parameters = {
    'kernel': ('linear', 'rbf'),
	'C': (1,4,8,16,32)
}
cv = 5

clf = GridSearchCV(svc, parameters, cv)
clf.fit(train_vectors, train_sentiment)
```

`clf` now holds the SVC model with the best hyperparameters amongst those that we provided (kernel and C)