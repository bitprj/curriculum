<!--title={Tokenization}-->

### Tokenization

* Tokenzation first breaks up a sentence into words
* Then places a level of importance of each word
* Lastly, produces a description of the input sentence. 

Example of Tokenization: 

First, import nltk. 

This can be done with 

```python
import os
import nltk
import nltk.corpus 
```

After we can simply input the command:

```python
print(os.listdir(nltk.data.find("corpora")))
```

Corpora is provided by the package nltk is simply data. When the command is printed, you will see a whole list of files that contain textual data, file names, functions.