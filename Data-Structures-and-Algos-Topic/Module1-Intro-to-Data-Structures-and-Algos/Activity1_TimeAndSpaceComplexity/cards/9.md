These are the official names of **Big-O** notation. They are all relatively similar, but are terms with their own unique purpose. The **Big O** we have been talking about this entire time is formally known as **Big Theta**. In the work and the industry, **Big Theta** is referred to as simply **Big O**. To avoid confusion, from now on, **Big Theta** will refer to the workplace Big-O and **Big (O)** will be the formal definition.   

#### What are they?

**Big (O)** is the upper bound of a function. It describes a function whose curve on a graph, at least after a certain point on the x-axis (input size), will always be higher on the y-axis (time) than the curve of the runtime.

To explain in simpler terms, let's say I have a chocolate bar. I give you half of the chocolate bar. Then I will have half of the chocolate is leftover. With the chocolate bar I have left over I give you another half and I keep repeating this process.

 Theoretically, this could go on forever, however if you add them all up you know that they will add up to one chocolate bar i.e it will **converge** to 1. We can set an *upper bound* for how much chocolate you have to be 1; we have just applied the **Big (O)** concept. No matter how long this exchange goes on for, I will always be holding onto some tiny bit of the chocolate. The amount of chocolate that you have won't actually be the entire bar, but you may be very close to it! 

We could have chosen our upper bound to be as high as we want. Let it be 1 million and we can say for 100% certainty that we won't be wrong. However, this isn't very useful because we are allowing such a wide range which is why it is best if we try to establish the smallest range possible. 

Let's apply this concept to Computer Science terms.

Let's say that `functionA` runs in **O(n^2) time**. If we compare it to `functionB` , which runs in **O(n!)** time, we know that `functionA`'s runtime will never exceed `functionB`'s runtime. 

![alt](https://cdn-media-1.freecodecamp.org/images/1*KfZYFUT2OKfjekJlCeYvuQ.jpeg)

You can see the runtime of **O(n)** never exceeds the runtime of **O(n!)**

##### Why is this useful? 

In the absolute worst case scenario, we know the ceiling of `functionA`'s runtime. We are then able to prepare for it and ensure that our computer or hardware will be able to handle running the function. 

